{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 처리 방법\n",
    ">- 1) 픽셀 기반 이미지 처리 :  픽셀 단위 처리\n",
    ">- 2) 블록 기반 처리 : 블록(픽셀을 그룹화 한것) 단위로 처리 - 필터\n",
    ">- 3) 주파수 기반 처리 : 주파수 영역으로 변환하여 처리 - FFT, DCT, WT 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253 249 248]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "px = img[200,200]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- img[200,200] : 픽셀의 좌표, 이미지는 2차원 배열로 나열되어 있음\n",
    "- Blue(253), Green(249), Red(248) 순서로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 픽셀값을 임의로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "img[200,200] = [0,255,0] # 픽셀값을 다른 값으로 변경\n",
    "\n",
    "cv2.imshow('model', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 픽셀값을 RGB 채널 값으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "img[200,200] = [0,255,0] # 픽셀값을 다른 값으로 변경\n",
    "\n",
    "#itemset( ( 픽셀 y 위치 , 픽셀 x 위치, 채널), 색상레벨 )\n",
    "img.itemset( (200, 100, 1), 255)\n",
    "\n",
    "cv2.imshow('model', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 채널 (0 : Blue, 1 : Green, 2 :Red )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 속성 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(770, 700, 3)\n",
      "1617000\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 영역 설정 (ROI : Region of Image) 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "cv2.imshow('original', img)\n",
    "\n",
    "# 이미지의 영역 설정\n",
    "# img[200:370, 200:350]   :  출력할 이미지 영역 설정\n",
    "subimg = img[0:370, 200:550] # y축 200~380, x축 200~350\n",
    "cv2.imshow('cutting', subimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB 채널 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "\n",
    "b = img[ : , : , 0]\n",
    "g = img[ : , : , 1]\n",
    "r = img[ : , : , 2]\n",
    "\n",
    "cv2.imshow('blue channel', b)\n",
    "cv2.imshow('green channel', g)\n",
    "cv2.imshow('red channel', r)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB 채널 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "\n",
    "b = img[ : , : , 0]\n",
    "g = img[ : , : , 1]\n",
    "r = img[ : , : , 2]\n",
    "\n",
    "merge_img = cv2.merge((b,g,r))\n",
    "\n",
    "cv2.imshow('merge', merge_img)\n",
    "cv2.imshow('green channel', g)\n",
    "cv2.imshow('red channel', r)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드로잉 ( 도형 그리기 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- cv2.line ( 배경이미지, 시작점 좌표, 끝점 좌표, 색상, 선두께 ) : 직선그리기 함수\n",
    ">- cv2.circle( 배경이미지, 중심좌표, 반지름, 색상, 선두께 ) : 원 그리기 함수\n",
    ">- cv2.rectangle ( 배경이미지, 좌상단 점 좌표, 우하단 점 좌표, 색상, 선두께 ) : 사각형 그리기 함수\n",
    ">- cv2.ellipse ( 배경이미지, 중심좌표, 장출/단호길이, 호의 시작각, 화의 종료각, 색상, 선두께 ) : 타원 그리기 함수\n",
    ">- cv2.putText( 배경이미지, 출력내용, 출력시작좌표(x,y) 폰트, 크기, 색상, 굵기 ) : 텍스트 입력함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"./data/img.jpg\")\n",
    "\n",
    "#사각형\n",
    "img = cv2.rectangle(img,(200,200), (400,400),(0,0,255),5)\n",
    "\n",
    "#텍스트\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX # 폰트 설정\n",
    "img = cv2.putText(img, 'Quokka', (100,200), font, 2, (0,255,255),4)\n",
    "cv2.imshow('rectangle', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./data/img.jpg')\n",
    "\n",
    "#폰트와 폰트 크기 설정\n",
    "font = ImageFont.truetype('fonts/gulim.ttc', 30)\n",
    "# 이미지를 PIL 이미지로 변환\n",
    "img_pil = Image.fromarray(img)\n",
    "# PIL이미지에 문자 출력\n",
    "draw = ImageDraw.Draw(img_pil)\n",
    "\n",
    "draw.text ( (200, 20), '나의사랑너의사랑우리쿼카싸랑해!!', font = font, fill=(0,0,255,0))\n",
    "\n",
    "#PIL 이미지를 numpy형태로 변환\n",
    "img = np.array(img_pil)\n",
    "\n",
    "cv2.imshow('font', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 합성하기(비트연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\core\\src\\arithm.cpp:250: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-974bb750a8b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmask_b_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mimg_bg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mimg_fg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_b_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mbg_fg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_bg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_fg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\core\\src\\arithm.cpp:250: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./data/img.jpg')\n",
    "mask = cv2.imread('./data/S2.png')\n",
    "\n",
    "rows, cols, channels = mask.shape\n",
    "roi = img[50: rows +50, 150:cols+150]\n",
    "\n",
    "mask2gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask_b = cv2.threshold(mask2gray, 200,250, cv2.THRESH_BINARY)\n",
    "\n",
    "mask_b_inv = cv2.bitwise_not(mask_b)\n",
    "img_bg = cv2.bitwise_and(roi, roi, mask = mask_b)\n",
    "img_fg = cv2.bitwise_and(mask, mask, mask=mask_b_inv)\n",
    "bg_fg = cv2.add(img_bg, img_fg)\n",
    "img[50:rows+50, 150:cols+150] = bg_fg\n",
    "cv2.imshow('result', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 색상 추적하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./data/img.jpg')\n",
    "cv2.imshow( 'Original', img)\n",
    "\n",
    "# HSV 색상공간으로 변형\n",
    "hsv = cv2.cvtColor (img, cv2.COLOR_BGR2HSV)\n",
    "# HSV 모델의 특정색상(red)의 lower에서 upper까지 범위 설정\n",
    "lower = np.array( [-10, 100, 100] )\n",
    "upper = np.array( [10, 255, 255])\n",
    "\n",
    "# mask 이미지로 HSV의 lower 에서 upper까지의 범위 색상을 마스크로 설정\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "# 저장된 이미지에서 mask 이미지( red 아닌 경우 0으로 채워진 이미지 ) 와 AND 연산\n",
    "img2 = cv2.bitwise_and(img, img, mask = mask)\n",
    "\n",
    "cv2.imshow( 'Extract Color', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.cvtColor (img, cv2.COLOR_BGR2HSV) : HSV 색상 공간으로 변경\n",
    "- cv2.inRange(hsv, lower, upper) : 범위에 해당하는 값이 아닌경우 0으로 채움\n",
    "- cv2.bitwise_and(img, img, mask = mask) : mask 값이 0이 아닌 부분만 AND 연산\n",
    "- HSV 모델의 blue : \n",
    "> lower = np.array( [110, 100, 100] )\n",
    "> upper = np.array( [130, 255, 255])\n",
    "- HSV 모델의 green :\n",
    "> lower = np.array([50, 100, 100])\n",
    "> upper = np.array([70, 255, 255])\n",
    "- HSV 모델의 red :\n",
    "> lower = np.array([-10, 100, 100])\n",
    "> upper = np.array([10, 255, 255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./data/img.jpg')\n",
    "cv2.imshow('master', img)\n",
    "#Kernel은 필터링할 마스크 생성 5X 5 생성하여 특정 숫자로 채운다\n",
    "#숫자값은 주변 픽셀과 연산을 하기 위한 실수값\n",
    "kernel = np.ones((5,5), np.float32)/25\n",
    "#cv2.filter2D(이미지,색상정보,마스크)\n",
    "#색상정보가 -1이면 원본 이미지 정보\n",
    "blur = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "cv2.imshow('blur', blur)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 침식과 팽창"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Erosion : 이미지의 경계부분을 배경 픽셀로 변경하는 작업\n",
    ">- Dilation : 이미지의 배경부분을 전경 픽셀로 변경하는 작업\n",
    ">- iteration = 1 : 반복 적용 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/img.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "erosion = cv2.erode(img, kernel, iterations = 2)\n",
    "dilation = cv2.dilate( img, kernel, iterations = 2)\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('erosion', erosion)\n",
    "cv2.imshow('dilation', dilation)\n",
    "k= cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening과 Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('./data/img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('./data/img2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow('originalA', img1)\n",
    "cv2.imshow('originalB', img2)\n",
    "\n",
    "#Opening : erosion 수행 후 바로 dilate을 수행하여 원래 이미지 크기로 돌려놓는 것\n",
    "#검은색에 가까운 이미지의 노이스 제거 효과\n",
    "#Closing : dilate 수행 후에 바로 erocion을 수행하여 원래 이미지 크기로 돌려놓는 것\n",
    "#흰색에 가까운 이미지의 노이스 제거 효과\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "opening = cv2.morphologyEx(img1,cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(img2,cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow('opening', opening)\n",
    "cv2.imshow('closing', closing)\n",
    "\n",
    "k= cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 에지 추출 - Canny 에지 추출기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./data/map.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "edge = cv2.Canny(img, 50, 200)\n",
    "cv2.imshow('edge', edge)\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 윤곽선 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\imgproc\\src\\drawing.cpp:2490: error: (-215:Assertion failed) 0 <= contourIdx && contourIdx < (int)last in function 'cv::drawContours'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4dfd85651edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# CHAIN_APPROX_SIMPLE ( 수평, 수직,대각선인 경우 중간의 점들은 버리고 끝점들만 남김)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m79\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'contour'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\imgproc\\src\\drawing.cpp:2490: error: (-215:Assertion failed) 0 <= contourIdx && contourIdx < (int)last in function 'cv::drawContours'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./data/map.png')\n",
    "gray = cv2.cvtColor (img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('gray',gray)\n",
    "#cv2.threshold(이미지,임계값,픽셀 최대값,임계값 적용방법)\n",
    "#이진 이미지 생성 (0인경우 임계값보다 크면 픽셀 최대값을 할당하고, 적으면 0을 할당)\n",
    "ret, thr = cv2.threshold(gray, 127, 255, 0)\n",
    "# RETR_TREE ( 모든 외곽선을 추출하고 외곽선 간의 상관관계 추출)\n",
    "# CHAIN_APPROX_SIMPLE ( 수평, 수직,대각선인 경우 중간의 점들은 버리고 끝점들만 남김)\n",
    "contours,_ = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img, contours, 79, (0,0,255), 1)\n",
    "cv2.imshow('contour', img)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.threshod ( 이미지, 임계값, 픽셀 최대값, 임계값 적용방법 )\n",
    "- 이진 이미지 생성 ( 0인 경우 임계값보다 크면 픽셀 최대값을 할당하고, 적으면 0을 할당)\n",
    "- cv2.findContours(이미지, 추출모드, 근사방법) \n",
    "- RETR_TREE ( 모든 외곽선을 추출하고 외곽선 간의 상관관계 추출)\n",
    "- CHAIN_APPROX_SIMPLE( 수평, 수직, 대각선인 경우 중간의 점들은 버리고 끝점들만 남김)\n",
    ">- contours를 찾는 방법\n",
    ">>- cv2.RETR_EXTERNAL :  contours line중 가장 바깥쪽 Line만 찾음\n",
    ">>- cv2.RETR_LIST     : 모든 contours line을 찾지만, hierarchy 관계를 구성하지 않음\n",
    ">>- cv2.RETR_CCMP :  모든 contours line을 찾으며, hierarcy 관계는 2-level로 구성함\n",
    ">>- cv2.RETR_TREE : 모든 contours line을 찾으며, 모든 hierarchy 관계를 구성함.\n",
    ">\n",
    ">- contours를 찾을 때 사용하는 근사치 방법\n",
    ">>- cv2.CHAIN_APPROX_NONE : 모든 contours point 를 저장\n",
    ">>- cv2.CHAIN_APPROX_SIMPLE : contours line을 그릴 수 있는 point만 저장(ex : 사각형이면 4개 point)\n",
    ">>- cv2.CHAIN_APPROX_TC89_L1 : contours point를 찾는 알고리즘\n",
    ">>- cv2.CHAIN_APPROX_TC89_KCOS : contours point를 찾는 알고리즘\n",
    ">\n",
    "- cv2.drawContours( 원본 이미지, 외곽선 값, 그릴 외곽선 인덱스, 외곽선 색상, 선의 두께) : 인덱스가 -1이면 모든 외곽선을 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 모멘트\n",
    "- 객체의 무게중심, 면적 등과 같은 특성을 구할 때 유용\n",
    "- 종류 : 공간 모멘트 (Sparial Moments), 중심 모멘트(Central Moments), 평준화된 중심 모멘트(Central Nomalized Moments)\n",
    "- cv2.moments( 윤곽선 데이터 ) 함수를 활용하여 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c712ab5e1c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mcontour\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmmt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'm00'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmmt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'm10'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmmt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'm01'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "contour = contours[3]\n",
    "mmt = cv2.moments( contour)\n",
    "\n",
    "print(mmt['m00'],mmt['m10'],mmt['m01'])\n",
    "\n",
    "# 윤곽선의 무게중심\n",
    "cx = int(mmt['m10']/mmt['m00'])\n",
    "cy = int(mmt['m01']/mmt['m00'])\n",
    "cv2.circle(img, (cx, cy), 2, (0,0,255), -1)\n",
    "\n",
    "cv2.imshow('contour_center', img)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 모멘트 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- 공간 모멘트(Spatal Moments)\n",
    ">>- m00, m10, m01, m11, m02, m30, m21, m12, m03\n",
    ">- 중심 모멘트(Central Moments)\n",
    ">>- mu20, mu11, mu02, mu30, mu21, mu12, mu03\n",
    ">-평준화된 중심 모멘트(Central Normalized Moments)\n",
    ">>- nu20, nu11, nu02, nu30, nu21, nu03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 윤곽선 면적과 길이 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윤곽선 면적 :  0.5\n",
      "윤곽선 길이 :  18.727921843528748\n"
     ]
    }
   ],
   "source": [
    "# 윤곽선 면적 계산\n",
    "contour_area = cv2.contourArea(contour)\n",
    "\n",
    "# 윤곽선의 길이 계산 (True : 윤곽선을 폐곡선으로 설정)\n",
    "contour_len = cv2.arcLength(contour, True)\n",
    "\n",
    "print(\"윤곽선 면적 : \" , contour_area)\n",
    "print(\"윤곽선 길이 : \", contour_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 윤곽선들의 면적 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14095.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "area = [cv2.contourArea(c) for c in contours]\n",
    "\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 윤곽선 근사화 ( 꼭지점 줄이기 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./data/map.png')\n",
    "img2 = img.copy()\n",
    "img3 = img.copy()\n",
    "imggray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thr = cv2.threshold( imggray , 200, 255, 0 )\n",
    "#contours, _ = cv2.findContours( thr , cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, hierachy = cv2.findContours(thr, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#cv2.drawContours(img, contours, 0 , (0,255,0), 2)\n",
    "cnt = contours[0]\n",
    "\n",
    "apsilon = 0.001 * cv2.arcLength( cnt, True)\n",
    "apsilon2 = 0.01 * cv2.arcLength( cnt, True)\n",
    "\n",
    "approx = cv2.approxPolyDP( cnt , apsilon , True )\n",
    "approx2 = cv2.approxPolyDP( cnt , apsilon2 , True )\n",
    "\n",
    "\n",
    "cv2.drawContours( img , [cnt], 0,(0,255,0) , 2)\n",
    "cv2.drawContours( img2 , [approx], 0,(0,255,0) , 2)\n",
    "cv2.drawContours( img3 , [approx2], 0,(0,255,0) , 2)\n",
    "#cv2.imshow('approx_contour', img)\n",
    "\n",
    "titles = ['Original', '1%', '10%']\n",
    "images = [img, img2, img3]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3, i+1)\n",
    "    plt.title(titles[i])\n",
    "    plt.imshow(images[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사각형, 원, 타원으로 외곽선 그리기\n",
    ">- x,y,w,h = cv2.boundingRect(contour) :사각형 윤곽선(시작좌표, 길이, 높이 반환)\n",
    "\n",
    ">- (x,y),r = minEnclosigCircle( cotour) : 원 윤곽선(중심좌표, 반지름 반환)\n",
    ">- ellipase = cv2.fitEllipase(contour) : 타원 윤곽선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-a853f8cea7fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/img.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimggray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mimggray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mthr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('model/img.jpg')\n",
    "imggray = cv2.cvtColor( img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thr = cv2.threshold( imggray, 100,255,0)\n",
    "contours, _ = cv2.findContours( thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img1=  img.copy()\n",
    "x,y,w,h = cv2.boundingRect(contours[4])\n",
    "cv2.rectangle(img1, (x,y), (x+h , y+h), (0,0,255),3)\n",
    "cv2.imshow('rect contour', img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 히스토그램(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-a76ba55f8e09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/talking.JPG'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'original'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcHist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('model/talking.JPG', cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('original', img)\n",
    "\n",
    "hist = cv2.calcHist( [img],[0],None, [256],[0,256])\n",
    "\n",
    "plt.plot(hist)\n",
    "plt.xlim([0,255])\n",
    "plt.show()\n",
    "k= cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 히스토그램 (Histogram) : 이미지의 색상을 벼라로 픽셀의 개수를 그래프로 표시한 것\n",
    "- Numpy, Matplotlib 라이브러리에서 함수를 제공하지만, OpenCV에서 제공하는 calcHist() 함수가 가장 성능이 좋음\n",
    ">- calcHist([이미지],[채널],특정마스크,[색상 개수],[픽셀값의 범위])\n",
    ">- 채널은 흑백영상인 경우는 0 , 칼라영상인 경우는 B(0), G(1), R(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 히스토그램 균일화\n",
    " - 색상 분포를 균일하게 변경하여 이미지의 콘트라스트를 강조하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-4b31afd26de7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequalizeHist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'equalize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcHist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.equalizeHist(img)\n",
    "cv2.imshow('equalize', img)\n",
    "\n",
    "hist = cv2.calcHist([img], [0], None, [256], [0,256])\n",
    "\n",
    "plt.plot(hist)\n",
    "plt.xlim([0,255])\n",
    "plt.show()\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 템플릿 매칭\n",
    " - 템플릿 매칭 : 어떤 이미지에서 템플릿 이미지와 매칭되는 부분이 있는지 검색하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-5171ea725900>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/majak.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/majak1.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 이미지의 크기를 반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('model/majak1.jpg')\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "temp = cv2.imread('model/majak.png', cv2.IMREAD_GRAYSCALE)\n",
    "# 이미지의 크기를 반환\n",
    "w,h = temp.shape[::-1]\n",
    "# matchTemplate( 원본 이미지, 부분 이미지, 매칭 방법)\n",
    "res = cv2.matchTemplate( imgray , temp, cv2.TM_CCOEFF_NORMED)\n",
    "# res가 0.7보다 큰 값들의 위치를 튜플로 반환\n",
    "loc = np.where( res >= 0.7)\n",
    "# 동일한 개수를 가진 리스트나 튜플을 같은 위치의 멤버들끼리 묶어서 튜플로 만든 다음 이를 멤버로 하는 리스트를 만듦\n",
    "for pt in zip(*loc[::-1]): # loc의 순서를 거꾸로하여 튜플을 묶고 리스트로만 옮긴다\n",
    "                            # x,y 좌표 순서가 바뀌므로\n",
    "    # cv2.rectangle(이미지, 시작위치, 종료 위치, 색상, 두께)\n",
    "    cv2.rectangle(img, pt, (pt[0]+w, pt[1]+h), (0,0,255),2)\n",
    "\n",
    "cv2.imshow('match', img)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### matchTemplate 옵션\n",
    "- TM_SQDIFF\n",
    "- TM_SQDIFF_NORMED\n",
    "- TM_CCORR\n",
    "- TM_CCORR_NORMED\n",
    "- TM_CCOEFF\n",
    "- TM_CCOEFF_NORMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하프변환을 이용하여 원 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./data/hough.jpg')\n",
    "\n",
    "imggray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv2.HoughCircles(imggray, cv2.HOUGH_GRADIENT, 1, 10, \n",
    "                          param1=60, param2=50, minRadius=10, maxRadius=100)\n",
    "\n",
    "if circles is not None:\n",
    "    \n",
    "    circles = np.uint16(np.around(circles))\n",
    "    \n",
    "    \n",
    "    for i in circles[0, :]:\n",
    "        cv2.circle(img, (i[0], i[1]), i[2], (255, 0, 0), 4)\n",
    "                   \n",
    "    cv2.imshow(\"Hough Circles\", img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()               \n",
    "else:\n",
    "    print(\"원이 없습니다\")                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, minDis, param1, param2, minRadius, maxRadius)\n",
    "  - cv2.HOUGH_GRADIENT : 원을 찾는 방법\n",
    "  - minDis : 원 중심들 간의 최소 거리 (0보다 커야 함)\n",
    "  - param1 : Canny 에지 추출자의 maxVal 값\n",
    "  - parma2 : 허프변환 카운팅 값 (너무 작으면 원하지 않는 많은 원들이 검출됨)\n",
    "  - minRadius : 원의 최소 반지름\n",
    "  - maxRadius : 원의 최대 반지름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB (Oriented FAST and Rotated BRIEF) 알고리즘\n",
    ">- ORB 알고리즘  : SIFT, SURF 대신에 자유롭게 사용할 수 있는 OpenCV의 이미지 특성 검출 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./data/bfly.png')\n",
    "imggray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img2 = None\n",
    "\n",
    "orb = cv2.ORB_create() # ORB객체 생성\n",
    "#img의 키포인트(영상의 특징점)들과 디스크립터( 키포인터 주변 영역의 특성을 표현하는 영상 표현자)를 계산\n",
    "kp, des = orb.detectAndCompute( img, None )\n",
    "\n",
    "\n",
    "img2 = img.copy()\n",
    "#키포인트 마커 그리기\n",
    "# markerType = 3 : 마커의 형태\n",
    "# markerSize = 10 : 마커 크기\n",
    "# thickness = 1  : 마커선 두께\n",
    "# color = (0,0,255) : 마커 색상\n",
    "for marker in kp :\n",
    "    img2 = cv2.drawMarker( img2, tuple(int(i) for i in marker.pt), \n",
    "                          markerType = 3,\n",
    "                          markerSize = 10,\n",
    "                          thickness = 1,\n",
    "                          color = (0,0,255))\n",
    "cv2.imshow('ORB', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB기반의 이미지 특성 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread(\"data/img.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"data/map.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "res = None\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, matches[:12], res, flags=0)\n",
    "\n",
    "cv2.imshow('matching', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global frame, frame2, inputmode, trackWindow, roi_hist, out\n",
    "\n",
    "try:\n",
    "    print('카메라를 구동합니다')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 480)\n",
    "    cap.set(4, 320)\n",
    "except:\n",
    "    print(\"카메라 구동 실패\")\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# 마우스 이벤트를 감지할 창의 이름을 설정\n",
    "cv2.namedWindow(\"frame\")\n",
    "# frame인 창에서 마우스 이벤트가 발생하면 onMouse 함수가 호출\n",
    "cv2.setMouseCallback(\"frame\", onMouse, param=(frame, frame2))\n",
    "\n",
    "# cv2.TERM_CRITERIA_EPS : 알고리즘의 반복회수 설정 (10회)\n",
    "# cv2.TERM_CRITERIA_COUNT : C1_o, C1_r이 차가 1pt일 때까지 반복\n",
    "termination = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"비디오 읽기 오류\")\n",
    "        break\n",
    "        \n",
    "    if trackWindow is not None:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)    \n",
    "        # 히스토그램의 역투사(backproject)를 계산 (원하는 영역의 색상만 추출)\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        \n",
    "        # trackWinodw에 해당하는 이동 객체를 추적\n",
    "        ret, trackWindow = cv2.CamShift(dst, trackWindow, termination)\n",
    "        \n",
    "        # 사각형 영역의 꼭지점 4개의 좌표를 반환\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        # 폴리곤이 그려질 이미지, 폴리곤의 꼭지점 좌표, 폐곡선 생성 여부, 색상, 두께\n",
    "        cv2.polylines(frame, [pts], True, (0, 255, 0), 2)\n",
    "                    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    k = cv2.waitKey(30) \n",
    "\n",
    "    # i라는 문자를 입력하면\n",
    "    if k == ord('i'):\n",
    "        print(\"추적할 영역을 설정하고 아무키나 누르세요\")\n",
    "        inputmode = True\n",
    "        frame2 = frame.copy()\n",
    "        \n",
    "        while inputmode:\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "            cv2.waitKey(0) \n",
    "        \n",
    "    if k == 49:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows() \n",
    "        break  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
