{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개와 고양이 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# =============================================\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth( gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)        \n",
    "# =============================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 이미지 데이터와 테스트 이미지 데이터 경로 설정\n",
    "train_cats_dir = './Data/cats_and_dogs_filtered/train/cats'\n",
    "train_dogs_dir = './Data/cats_and_dogs_filtered/train/dogs'\n",
    "test_cats_dir  = './Data/cats_and_dogs_filtered/test/cats'\n",
    "test_dogs_dir  = './Data/cats_and_dogs_filtered/test/dogs'\n",
    "predict_data_dir  = './Data/cats_and_dogs_filtered/predict' # 예측 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './Data/cats_and_dogs_filtered/train/cats'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-38afe26b2981>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 경로 내에 있는 파일 목록을 리스트로 생성한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_cats_fnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_cats_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cats_fnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_dogs_fnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_dogs_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dogs_fnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './Data/cats_and_dogs_filtered/train/cats'"
     ]
    }
   ],
   "source": [
    "# 경로 내에 있는 파일 목록을 리스트로 생성한다.\n",
    "train_cats_fnames = os.listdir( train_cats_dir)\n",
    "print(train_cats_fnames[:5])\n",
    "train_dogs_fnames = os.listdir( train_dogs_dir)\n",
    "print(train_dogs_fnames[:5])\n",
    "test_cats_fnames = os.listdir( test_cats_dir)\n",
    "print(test_cats_fnames[:5])\n",
    "test_dogs_fnames = os.listdir( test_dogs_dir)\n",
    "print(test_dogs_fnames[:5])\n",
    "predict_data_fnames = os.listdir( predict_data_dir) # 예측데이터 파일목록 가져오기\n",
    "print(predict_data_fnames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 불러오기 (train 2000장, test 1000장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join( train_cats_dir , train_cats_fnames[0])\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows =2 , ncols = 5, figsize = (15,5))\n",
    "im1 = os.path.join( train_cats_dir, train_cats_fnames[0])\n",
    "axes[0][0].imshow( Image.open(im1) )\n",
    "im2 = os.path.join( train_cats_dir, train_cats_fnames[1])\n",
    "axes[0][1].imshow( Image.open(im2) )\n",
    "im3 = os.path.join( train_cats_dir, train_cats_fnames[2])\n",
    "axes[0][2].imshow( Image.open(im3) )\n",
    "im4 = os.path.join( train_cats_dir, train_cats_fnames[3])\n",
    "axes[0][3].imshow( Image.open(im4) )\n",
    "im5 = os.path.join( train_cats_dir, train_cats_fnames[4])\n",
    "axes[0][4].imshow( Image.open(im5) )\n",
    "\n",
    "im6 = os.path.join( train_dogs_dir, train_dogs_fnames[0])\n",
    "axes[1][0].imshow( Image.open(im6) )\n",
    "im7 = os.path.join( train_dogs_dir, train_dogs_fnames[1])\n",
    "axes[1][1].imshow( Image.open(im7) )\n",
    "im8 = os.path.join( train_dogs_dir, train_dogs_fnames[2])\n",
    "axes[1][2].imshow( Image.open(im8) )\n",
    "im9 = os.path.join( train_dogs_dir, train_dogs_fnames[3])\n",
    "axes[1][3].imshow( Image.open(im9) )\n",
    "im10 = os.path.join( train_dogs_dir, train_dogs_fnames[4])\n",
    "axes[1][4].imshow( Image.open(im10) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 사이즈를 동일 사이즈로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows =2 , ncols = 5, figsize = (15,5))\n",
    "im1 = os.path.join( train_cats_dir, train_cats_fnames[0])\n",
    "axes[0][0].imshow( Image.open(im1).resize((224,224)) )\n",
    "im2 = os.path.join( train_cats_dir, train_cats_fnames[1])\n",
    "axes[0][1].imshow( Image.open(im2).resize((224,224)) )\n",
    "im3 = os.path.join( train_cats_dir, train_cats_fnames[2])\n",
    "axes[0][2].imshow( Image.open(im3).resize((224,224)) )\n",
    "im4 = os.path.join( train_cats_dir, train_cats_fnames[3])\n",
    "axes[0][3].imshow( Image.open(im4).resize((224,224)) )\n",
    "im5 = os.path.join( train_cats_dir, train_cats_fnames[4])\n",
    "axes[0][4].imshow( Image.open(im5).resize((224,224)) )\n",
    "\n",
    "im6 = os.path.join( train_dogs_dir, train_dogs_fnames[0])\n",
    "axes[1][0].imshow( Image.open(im6).resize((224,224)) )\n",
    "im7 = os.path.join( train_dogs_dir, train_dogs_fnames[1])\n",
    "axes[1][1].imshow( Image.open(im7).resize((224,224)) )\n",
    "im8 = os.path.join( train_dogs_dir, train_dogs_fnames[2])\n",
    "axes[1][2].imshow( Image.open(im8).resize((224,224)) )\n",
    "im9 = os.path.join( train_dogs_dir, train_dogs_fnames[3])\n",
    "axes[1][3].imshow( Image.open(im9).resize((224,224)) )\n",
    "im10 = os.path.join( train_dogs_dir, train_dogs_fnames[4])\n",
    "axes[1][4].imshow( Image.open(im10).resize((224,224)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로와 파일이름, 리사이즈를 수행할 사이즈 정보를 넘겨서 \n",
    "# 이미지 크기를 재 설정 한다.\n",
    "def load_images( default_path, filenames, resize_shape):\n",
    "    images = []\n",
    "    \n",
    "    for fname in filenames:\n",
    "        # 파일 경로 조립\n",
    "        filepath = os.path.join(default_path, fname) \n",
    "        # 이미지 크기 재설정\n",
    "        image = Image.open(filepath).resize(resize_shape) \n",
    "        # 이미지를 numpy 배열로 변경\n",
    "        images.append(np.array(image))               \n",
    "    # 전체 이미지 리스트를 numpy 배열로 반환한다\n",
    "    return np.array(images)              \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cats = load_images( train_cats_dir, train_cats_fnames,(224,224))\n",
    "X_train_dogs = load_images( train_dogs_dir, train_dogs_fnames,(224,224))\n",
    "X_test_cats  = load_images( test_cats_dir,  test_cats_fnames ,(224,224))\n",
    "X_test_dogs  = load_images( test_dogs_dir,  test_dogs_fnames ,(224,224))\n",
    " # 예측데이터 균일사이즈로 변환\n",
    "Predict_Data  = load_images( predict_data_dir,  predict_data_fnames ,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cats.shape, X_train_dogs.shape, X_test_cats.shape, X_test_dogs.shape, Predict_Data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train_cats, X_train_dogs))\n",
    "X_test  = np.concatenate((X_test_cats , X_test_dogs))\n",
    "\n",
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 설정( 고양이 : 0 , 개 : 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array( [0]*1000 + [1]*1000)\n",
    "y_test  = np.array( [0]*500 + [1]*500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy zip 형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed( './cat_dog',\n",
    "                    X_train = X_train,\n",
    "                    X_test = X_test,\n",
    "                    y_train = y_train,\n",
    "                    y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy zip  로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load( './cat_dog.npz')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검증 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 셋을 8:2로 나누어 검증용 데이터 셋을 생성\n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train, \n",
    "                                                   y_train, \n",
    "                                                   test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#               필터(커널)수 , 필터(커널) 사이즈,  \n",
    "model.add( Conv2D( 32 , kernel_size = (3,3),\n",
    "                   input_shape = (224,224,3),\n",
    "                   activation = 'relu',\n",
    "                   padding = 'same'))\n",
    "model.add( MaxPool2D( pool_size = 2))\n",
    "# ===========================================\n",
    "model.add( Conv2D( 64 , kernel_size = ( 3,3),\n",
    "                   activation = 'relu',\n",
    "                   padding = 'same'))\n",
    "model.add( MaxPool2D( pool_size = 2))\n",
    "# ===========================================\n",
    "model.add( Conv2D( 128 , kernel_size = ( 3,3),\n",
    "                   activation = 'relu',\n",
    "                   padding = 'same'))\n",
    "model.add( MaxPool2D( pool_size = 2))\n",
    "# ===========================================\n",
    "model.add( Conv2D( 64 , kernel_size = ( 3,3),\n",
    "                   activation = 'relu',\n",
    "                   padding = 'same'))\n",
    "model.add( MaxPool2D( pool_size = 2))\n",
    "# ===========================================\n",
    "model.add( Flatten())\n",
    "# ===========================================\n",
    "\n",
    "# ================ MLP ======================\n",
    "model.add(Dense( 512, activation= 'relu'))\n",
    "model.add(Dense( 1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 컴파일\n",
    "#### tf.keras.optimizer.Adam(lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( loss = 'binary_crossentropy',\n",
    "               optimizer = tf.keras.optimizers.Adam(lr = 0.0001),\n",
    "               metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_accuracy',\n",
    "                             patience=15)\n",
    "path = \"./Model/CNN_catsndogs_{epoch:03d}_{val_accuracy:.4f}.hdf5\"\n",
    "\n",
    "modelCheckPoint = ModelCheckpoint(filepath=path,\n",
    "                                 monitor='val_accuracy',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit( X_train , y_train,\n",
    "                     epochs = 50,\n",
    "                     validation_data = ( X_val , y_val),\n",
    "                     batch_size = 32,\n",
    "                     callbacks = [earlyStopping, modelCheckPoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = load_model('./Model/CNN_catsndogs_004_0.7000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.evaluate( X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과대적합 방지 ( 드롭아웃, 데이터 부풀리기 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# =================================================\n",
    "model2.add(Conv2D( 32, kernel_size = (3,3),\n",
    "                   input_shape = ( 224, 224, 3),\n",
    "                   activation = 'relu',\n",
    "                   padding = 'same'))\n",
    "model2.add(Conv2D( 32, kernel_size = (3,3),\n",
    "                  activation = 'relu',\n",
    "                  padding = 'same'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(MaxPool2D( pool_size = 2))\n",
    "# =================================================\n",
    "model2.add(Conv2D( 64, kernel_size = (3,3),\n",
    "                  activation = 'relu',\n",
    "                  padding = 'same'))\n",
    "model2.add(Conv2D( 64, kernel_size = (3,3),\n",
    "                  activation = 'relu',\n",
    "                  padding = 'same'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(MaxPool2D( pool_size = 2))\n",
    "# =================================================\n",
    "model2.add(Conv2D( 128, kernel_size = (3,3),\n",
    "                  activation = 'relu',\n",
    "                  padding = 'same'))\n",
    "model2.add(Conv2D( 128, kernel_size = (3,3),\n",
    "                  activation = 'relu',\n",
    "                  padding = 'same'))\n",
    "model2.add(MaxPool2D( pool_size = 2))\n",
    "# =================================================\n",
    "model2.add(Conv2D( 256, kernel_size = (3,3),\n",
    "                  activation = 'relu',\n",
    "                  padding = 'same'))\n",
    "model2.add(Conv2D( 256, kernel_size = (3,3),\n",
    "                  activation = 'relu',\n",
    "                  padding = 'same'))\n",
    "model2.add(MaxPool2D( pool_size = 2))\n",
    "model2.add(Dropout(0.3))\n",
    "# =================================================\n",
    "model2.add(Flatten())\n",
    "\n",
    "# =================== MLP =========================\n",
    "model2.add(Dense(512, activation = 'relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense( 1 , activation = 'sigmoid'))\n",
    "\n",
    "# =================== Model Compile ===============\n",
    "model2.compile( loss = 'binary_crossentropy',\n",
    "                optimizer = tf.keras.optimizers.Adam(lr = 0.0001),\n",
    "                metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator( rotation_range = 90,\n",
    "                              width_shift_range = 0.1,\n",
    "                              zoom_range = 0.3,\n",
    "                              vertical_flip = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_set = img_gen.flow(X_val, y_val, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit_generator( img_gen.flow( X_train, y_train , batch_size = 16),\n",
    "                      steps_per_epoch = 100, \n",
    "                      epochs = 20,\n",
    "                      validation_data= ( val_img_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate( X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_set = img_gen.flow_from_directory('./Data/cats_and_dogs_filtered/predict',\n",
    "                                              target_size = (224,224),\n",
    "                                              batch_size = 16,\n",
    "                                              class_mode ='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_predict = model2.predict_generator( Predict_Data ) # 예측데이터 넣기\n",
    "print(result_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix\n",
    "#print( confusion_matrix( result_predict , [1,1,1,1,1,0,0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_predict_class = model2.predict_classes( Predict_Data) # 분류값으로출력 \n",
    "print(result_predict_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
